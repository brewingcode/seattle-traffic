#!/usr/bin/env python

import os
import re
import pymongo
from bs4 import BeautifulSoup
from attrdict import AttrDict
import json
import datetime
import sys
from bson import json_util

config = AttrDict({
  'collection':None,
  'data_dir':None
})

def main():
  set_config()
  if len(sys.argv) > 1:
    if re.search(r'html', sys.argv[1], flags=re.I):
      return from_html()
    elif re.search(r'json', sys.argv[1], flags=re.I):
      return to_json()
  raise Exception('need to know if I am scraping HTML, or generating JSON')

def from_html():
  points = [AttrDict({'utc':datetime.datetime.utcnow(), 'local':'150910-1342', 'times':[1,2,3]})]
  # read files from data_dir, which is a series of html fragments
  insert(points)

def to_json():
  points = [mtj(p) for p in config.collection.find({})]
  here = os.path.dirname(os.path.realpath(__file__))
  with open(here + '/assets/data.json', 'w') as f:
    json.dump(points, f, default=json_util.default)

def mtj(o):
  return AttrDict({k:o[k] for k in ('utc', 'local', 'times')})

def set_config():
  global config
  hostname = re.sub(r'^([^.]+).*', r'\1', os.uname()[1]).lower()
  client = pymongo.MongoClient('localhost', opts[hostname][0])
  config.collection = client.alex.travel_times
  config.data_dir = opts[hostname][1]

def insert(records):
  reqs = []
  for r in records:
    reqs.append(pymongo.ReplaceOne({'local':r.local}, r, upsert=True))
  res = config.collection.bulk_write(reqs)
  for stat in ['deleted', 'inserted', 'matched', 'modified', 'upserted']:
    print '{}: {}'.format(stat, getattr(res, stat+'_count'))

if __name__ == '__main__':
  main()
