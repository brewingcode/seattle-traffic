#!/usr/bin/env python

import os
import re
import pymongo
from bs4 import BeautifulSoup
from attrdict import AttrDict
import json
import datetime
import pytz
import sys
from bson import json_util

config = AttrDict({
  'mongo_host':None,
  'collection':None,
  'data_dir':None
})

count = {}

here = os.path.dirname(os.path.realpath(__file__))

def main():
  set_config()
  if len(sys.argv) > 1:
    if re.search(r'html', sys.argv[1], flags=re.I):
      return from_html()
    elif re.search(r'routes', sys.argv[1], flags=re.I):
      return to_routes()
    elif re.search(r'timing', sys.argv[1], flags=re.I):
      return to_timing()
  raise Exception('need to know if I am scraping HTML, generating routes, or generating timing data')

def from_html():
  existing = {d['local']:1 for d in config.collection.find({}, {'local':1})}
  print "found {} existing timestamps".format(len(existing.keys()))
  os.system('mkdir -p {}/finished'.format(config.data_dir))

  records = []
  finished = []
  count = 0
  for filename in os.listdir(config.data_dir):
    if filename == 'finished':
      continue

    count += 1
    if filename not in existing:
      records.extend([p for p in parse(filename) if p is not None])
    finished.append(filename)
    sys.stdout.write('\r{}'.format(count))
    sys.stdout.flush()

  print ''
  temp_file = '/tmp/travel_times.json'
  import_cmd = 'mongoimport --jsonArray -h {} -d alex {}'.format(config.mongo_host, temp_file)
  write_json(records, temp_file)

  os.system(import_cmd)

  for f in finished:
    os.system('mv {0}/{1} {0}/finished'.format(config.data_dir, f))

# yields multiple times, with value of either None or an AttrDict
def parse(filename):
  local = pytz.timezone ("America/Los_Angeles")
  naive = datetime.datetime.strptime('20'+filename, '%Y%m%d-%H%M')
  local_dt = local.localize(naive, is_dst=None)
  utc_dt = local_dt.astimezone (pytz.utc)

  with open(config.data_dir + '/' + filename) as f:
    html = f.read()

  if len(html) > 10 or re.search(r'Travel Times Currently Unavailable', html):
    yield None

  soup = BeautifulSoup(html)
  prev = AttrDict({
    'start':'',
    'end':'',
    'via':''
  })

  for row in soup.select('tr')[1:]:
    data = AttrDict({
      'local':filename,
      'utc':utc_dt,
      'start':None,
      'end':None,
      'via':None,
      'distance':None,
      'average':None,
      'current':None,
      'hov':None
    })

    def number_parse(index):
      val = re.sub(r'\s', '', tds[index].get_text())
      try:
        val = float(val)
      except:
        val = 0.0
      return int(val) if float.is_integer(val) else val

    tds = row.select('td')
    m = re.search(r'(.*?) to (.*)', tds[1].get_text())
    express = True if re.search(r'express lanes', tds[0].get_text(), re.I) else False
    offset = -1 if express else 0

    data.start = m.group(1) if m else prev.start
    data.end = m.group(2) if m else prev.end

    if express:
      data.via = prev.via + ' (E)'
    else:
      data.via = ', '.join([t['alt'] for t in tds[0].select('img[alt]')])
      prev.via = data.via

    data.distance = number_parse(2+offset)
    data.average = number_parse(3+offset)
    data.current = number_parse(4+offset)
    data.hov = number_parse(5+offset)

    yield data
    prev.start = data.start
    prev.end = data.end

def write_json(data, filename):
  with open(filename, 'w') as f:
    json.dump(data, f, default=json_util.default)
    print filename

def to_routes():
  routes = {}
  cities = sorted([x for x in config.collection.distinct('start')])
  for start in cities:
    for end in cities:
      if start == end: continue

      if start not in routes:
        routes[start] = {}
      if end not in routes[start]:
        routes[start][end] = None

      # don't go re-querying for distinct data we already have
      if end in routes and routes[end][start] is not None:
        routes[start][end] = routes[end][start]
      else:
        print "{}->{}".format(start, end)
        routes[start][end] = [x for x in config.collection.distinct('via', {'start':start, 'end':end})]

  write_json(routes, here+'/assets/routes.json')

def to_timing():
  with open(here+'/assets/routes.json', 'r') as f:
    routes = json.load(f)

  for start in routes.keys():
    for end in routes[start].keys():
      directory = 'assets/timing/{}/{}'.format(start,end)
      try:
        os.makedirs(directory)
      except:
        pass
      for route in routes[start][end]:
        build_timing_json(start, end, route, '{}/{}/{}.json'.format(here, directory, route))

def build_timing_json(start, end, route, filename):
  times = [x for x in config.collection
    .find({'start':start, 'end':end, 'via':route}, {'utc':1, 'current':1})
    .sort('utc', pymongo.ASCENDING)
  ]
  stripped = []
  for t in times:
    stripped.append({
      'u':int((t['utc'] - datetime.datetime(1970,1,1)).total_seconds()),
      't':t['current']
    })
  print "{} time points".format(len(times))
  write_json(stripped, filename)

def set_config():
  global config

  hostname = re.sub(r'^([^.]+).*', r'\1', os.uname()[1]).lower()
  config.mongo_host = opts[hostname][0]
  client = pymongo.MongoClient(config.mongo_host, socketKeepAlive=True)
  config.collection = client.alex.travel_times
  config.data_dir = opts[hostname][1]

def insert(records):
  global count
  reqs = []
  for r in records:
    reqs.append(pymongo.ReplaceOne({'id':r.id}, r, upsert=True))
  res = config.collection.bulk_write(reqs)
  for stat in ['deleted', 'inserted', 'matched', 'modified', 'upserted']:
    attr = stat + '_count'
    if attr not in count:
      count[attr] = 0
    if int(getattr(res, attr)) > 0:
      count[attr] += int(getattr(res, attr))
      print '{}\t{}\t{}'.format(stat, getattr(res, stat+'_count'), count[attr])

if __name__ == '__main__':
  main()
